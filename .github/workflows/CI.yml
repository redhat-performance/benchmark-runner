# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: CI

on:
  push:
    branches: [ main ]
  #pull_request:
  #  branches: [ main ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest pytest-cov
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f tests_requirements.txt ]; then pip install -r tests_requirements.txt; fi
    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    - uses: azure/k8s-set-context@v1
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBECONFIG }} # Use secret (https://developer.github.com/actions/managing-workflows/storing-secrets/)
      id: setcontext
    - name: 📃 Test with pytest
      env:
        KUBEADMIN_PASSWORD: ${{ secrets.KUBEADMIN_PASSWORD }}
        PIN_NODE1: ${{ secrets.PIN_NODE1 }}
        PIN_NODE2: ${{ secrets.PIN_NODE2 }}
        RUNNER_PATH: ${{ secrets.RUNNER_PATH }}
        ELASTICSEARCH: ${{ secrets.ELASTICSEARCH }}
        ELASTICSEARCH_PORT: ${{ secrets.ELASTICSEARCH_PORT }}
        AZURE_CLIENTID: ${{ secrets.AZURE_CLIENTID }}
        AZURE_SECRET: ${{ secrets.AZURE_SECRET }}
        AZURE_TENANTID: ${{ secrets.AZURE_TENANTID }}
        AZURE_SUBSCRIPTIONID: ${{ secrets.AZURE_SUBSCRIPTIONID }}
        AZURE_RESOURCE_GROUP_NAME: ${{ secrets.AZURE_RESOURCE_GROUP_NAME }}
        AZURE_VM_NAME: ${{ secrets.AZURE_VM_NAME }}
        AZURE_CLUSTER_VM_NAME_LIST: ${{ secrets.AZURE_CLUSTER_VM_NAME_LIST }}
      run: |
        echo ">>>>>>> Start Azure cluster VMs before tests"
        declare -a AZURE_CLUSTER_VM_NAME_LIST=$AZURE_CLUSTER_VM_NAME_LIST
        for AZURE_VM_NAME in "${AZURE_CLUSTER_VM_NAME_LIST[@]}"
        do
            echo 'START vm:' $AZURE_VM_NAME
            podman run --rm -e AZURE_CLUSTER_START=true -e AZURE_CLIENTID=$AZURE_CLIENTID -e AZURE_SECRET=$AZURE_SECRET -e AZURE_TENANTID=$AZURE_TENANTID -e AZURE_SUBSCRIPTIONID=$AZURE_SUBSCRIPTIONID -e AZURE_RESOURCE_GROUP_NAME=$AZURE_RESOURCE_GROUP_NAME -e AZURE_VM_NAME=$AZURE_VM_NAME -e log_level=INFO quay.io/ebattat/benchmark-runner:latest
            sleep 60
        done

        # Install Dockerfile content for pytest
        # install oc/kubctl
        oc_version=4.7.0-0.okd-2021-05-22-050008
        curl -L https://github.com/openshift/okd/releases/download/${oc_version}/openshift-client-linux-${oc_version}.tar.gz -o $RUNNER_PATH/openshift-client-linux-${oc_version}.tar.gz
        tar -xzvf $RUNNER_PATH/openshift-client-linux-${oc_version}.tar.gz -C $RUNNER_PATH/
        rm $RUNNER_PATH/openshift-client-linux-${oc_version}.tar.gz
        echo alias oc=$RUNNER_PATH/./oc >> $RUNNER_PATH/.bashrc
        echo alias kubectl=$RUNNER_PATH/./kubectl >> $RUNNER_PATH/.bashrc

        # install helm
        curl -fsSL -o $RUNNER_PATH/get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
        chmod 700 $RUNNER_PATH/get_helm.sh
        $RUNNER_PATH/./get_helm.sh
        echo alias helm=/usr/local/bin/helm >> $RUNNER_PATH/.bashrc
        source $RUNNER_PATH/.bashrc

        # clone benchmark-operator
        git clone https://github.com/cloud-bulldozer/benchmark-operator $RUNNER_PATH/benchmark-operator
        # Insufficient cpu - Patch for functional Azure env with 8 cpu - resource limit cpu 0 instead of 2 (also in Dockerfile)
        sed -i -e 's/2.0/0.0/g' $RUNNER_PATH/benchmark-operator/config/manager/manager.yaml

        # run pytest
        pytest --cov=benchmark_runner --cov-report=term-missing
        coverage run -m pytest
        sleep 60
        coverage report -m
    - name: 🎥 Publish to coveralls.io
      env:
        GITHUB_TOKEN: ${{ secrets.GIT_TOKEN }}
      run: |
        pip install coveralls
        COVERALLS_REPO_TOKEN=${{ secrets.COVERALLS_REPO_TOKEN }} coveralls
    - name: 🔨 Build and publish distribution 📦 to PyPI
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
      run: |
        pip install setuptools wheel twine
        python setup.py sdist bdist_wheel
        twine upload dist/*
        echo '⌛ Wait 30 sec till package will be updated in PyPI'
        sleep 30
    - name: ⌛ Upload 🐋 to quay.io
      run: |
        version=$(python3 setup.py --version)
        sudo podman build --build-arg VERSION=$version --layers=false -t ${{ secrets.PACKAGE_NAME }}:v$version .
        sudo podman login quay.io -u ${{ secrets.QAUYIO_ROBOT_USER }} -p ${{ secrets.QAUYIO_ROBOT_TOKEN }}
        sudo podman push localhost/${{ secrets.PACKAGE_NAME }}:v$version quay.io/${{ secrets.QAUYIO_REPOSITORY }}/${{ secrets.PACKAGE_NAME }}:v$version
        sudo podman push localhost/${{ secrets.PACKAGE_NAME }}:v$version quay.io/${{ secrets.QAUYIO_REPOSITORY }}/${{ secrets.PACKAGE_NAME }}
        echo '⌛ Wait 30 sec till image will be updated in quay.io'
        sleep 30
    - name: ✔️ E2E tests using latest quay.io
      env:
        KUBEADMIN_PASSWORD: ${{ secrets.KUBEADMIN_PASSWORD }}
        PIN_NODE_BENCHMARK_OPERATOR: ${{ secrets.PIN_NODE_BENCHMARK_OPERATOR }}
        PIN_NODE1: ${{ secrets.PIN_NODE1 }}
        PIN_NODE2: ${{ secrets.PIN_NODE2 }}
        ELASTICSEARCH: ${{ secrets.ELASTICSEARCH }}
        ELASTICSEARCH_PORT: ${{ secrets. ELASTICSEARCH_PORT }}
        AZURE_CLIENTID: ${{ secrets.AZURE_CLIENTID }}
        AZURE_SECRET: ${{ secrets.AZURE_SECRET }}
        AZURE_TENANTID: ${{ secrets.AZURE_TENANTID }}
        AZURE_SUBSCRIPTIONID: ${{ secrets.AZURE_SUBSCRIPTIONID }}
        AZURE_RESOURCE_GROUP_NAME: ${{ secrets.AZURE_RESOURCE_GROUP_NAME }}
        AZURE_CLUSTER_VM_NAME_LIST: ${{ secrets.AZURE_CLUSTER_VM_NAME_LIST }}
      run: |
        BUILD_VERSION=$(python3 setup.py --version)
        declare -a WORKLOADS=('stressng_pod' 'stressng_vm' 'uperf_pod' 'uperf_vm' 'hammerdb_pod_mariadb' 'hammerdb_vm_mariadb' 'hammerdb_pod_postgres' 'hammerdb_vm_postgres' 'hammerdb_pod_mssql' 'hammerdb_vm_mssql')
        for WORKLOAD in "${WORKLOADS[@]}"
        do
            echo '>>>>>>>>>>>>>>>>>>>>>>>>>> Start E2E workload:' $WORKLOAD '>>>>>>>>>>>>>>>>>>>>>>>>>>'
            podman run --rm -e WORKLOAD=$WORKLOAD -e KUBEADMIN_PASSWORD=$KUBEADMIN_PASSWORD -e PIN_NODE_BENCHMARK_OPERATOR=$PIN_NODE_BENCHMARK_OPERATOR -e PIN_NODE1=$PIN_NODE1 -e PIN_NODE2=$PIN_NODE2 -e ELASTICSEARCH=$ELASTICSEARCH -e ELASTICSEARCH_PORT=$ELASTICSEARCH_PORT -e BUILD_VERSION=$BUILD_VERSION -e log_level=INFO -v $KUBECONFIG:/root/.kube/config --privileged quay.io/ebattat/benchmark-runner:v$BUILD_VERSION
            echo '>>>>>>>>>>>>>>>>>>>>>>>>>> End E2E workload:' $WORKLOAD '>>>>>>>>>>>>>>>>>>>>>>>>>>>>'
        done
        echo ">>>>>>> Stop Azure cluster after tests"
        declare -a AZURE_CLUSTER_VM_NAME_LIST=$AZURE_CLUSTER_VM_NAME_LIST
        for AZURE_VM_NAME in "${AZURE_CLUSTER_VM_NAME_LIST[@]}"
        do
            echo 'STOP vm:' $AZURE_VM_NAME
            podman run --rm -e AZURE_CLUSTER_STOP=true -e AZURE_CLIENTID=$AZURE_CLIENTID -e AZURE_SECRET=$AZURE_SECRET -e AZURE_TENANTID=$AZURE_TENANTID -e AZURE_SUBSCRIPTIONID=$AZURE_SUBSCRIPTIONID -e AZURE_RESOURCE_GROUP_NAME=$AZURE_RESOURCE_GROUP_NAME -e AZURE_VM_NAME=$AZURE_VM_NAME -e log_level=INFO quay.io/ebattat/benchmark-runner:v$BUILD_VERSION
        done
    - name: 🎁 Bump Version
      run: |
        version=$(python3 setup.py --version)
        git checkout main
        pip install bumpversion
        git config --global user.email ${{ secrets.EMAIL }}
        git config --global user.name  ${{ secrets.NAME }}
        bumpversion patch
        # GITHUB_REPOSITORY already taken => GIT_REPOSITORY
        git commit .bumpversion.cfg setup.py -m 'bump version to exist version v'$version
        git pull https://${{ secrets.GIT_TOKEN }}@${{ secrets.GIT_REPOSITORY}} main
        git push https://${{ secrets.GIT_TOKEN }}@${{ secrets.GIT_REPOSITORY}} main
        git push https://${{ secrets.GIT_TOKEN }}@${{ secrets.GIT_REPOSITORY}} --tag
    - name: Stop Azure cluster when the job has failed
      env:
        AZURE_CLIENTID: ${{ secrets.AZURE_CLIENTID }}
        AZURE_SECRET: ${{ secrets.AZURE_SECRET }}
        AZURE_TENANTID: ${{ secrets.AZURE_TENANTID }}
        AZURE_SUBSCRIPTIONID: ${{ secrets.AZURE_SUBSCRIPTIONID }}
        AZURE_RESOURCE_GROUP_NAME: ${{ secrets.AZURE_RESOURCE_GROUP_NAME }}
        AZURE_CLUSTER_VM_NAME_LIST: ${{ secrets.AZURE_CLUSTER_VM_NAME_LIST }}
      if: ${{ failure() }}
      run: |
        echo ">>>>>>> Stop Azure cluster after failure"
        declare -a AZURE_CLUSTER_VM_NAME_LIST=$AZURE_CLUSTER_VM_NAME_LIST
        for AZURE_VM_NAME in "${AZURE_CLUSTER_VM_NAME_LIST[@]}"
        do
            echo 'STOP vm:' $AZURE_VM_NAME
            podman run --rm -e AZURE_CLUSTER_STOP=true -e AZURE_CLIENTID=$AZURE_CLIENTID -e AZURE_SECRET=$AZURE_SECRET -e AZURE_TENANTID=$AZURE_TENANTID -e AZURE_SUBSCRIPTIONID=$AZURE_SUBSCRIPTIONID -e AZURE_RESOURCE_GROUP_NAME=$AZURE_RESOURCE_GROUP_NAME -e AZURE_VM_NAME=$AZURE_VM_NAME -e log_level=INFO quay.io/ebattat/benchmark-runner:latest
        done
